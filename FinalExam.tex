\documentclass[12pt]{article}
\usepackage[margin=1in]{geometry} 
\usepackage{amsmath,amsthm,amssymb,amsfonts}
\newcommand{\N}{\mathbb{N}}
\newcommand{\Z}{\mathbb{Z}}
\newcommand{\R}{\mathbb{R}}
\newcommand{\lra}{\Longrightarrow}
\newenvironment{problem}[2][Problem]{\begin{trivlist}
  \item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries #2:}]}{\end{trivlist}}
\newenvironment{subproblem}[2][Part]{\begin{trivlist}
  \item[\hskip \labelsep {\bfseries #1}\hskip \labelsep {\bfseries (#2)}]}{\end{trivlist}}
\newenvironment{solution}[1][Solution]{\begin{trivlist}
  \item[\hskip \labelsep {\bfseries #1} \hskip \labelsep]}{\end{trivlist}}

\theoremstyle{remark}
\newtheorem*{theorem*}{Theorem}

\begin{document}
 
\title{Math 4990 - Final Exam}
\author{Kevin Kim t00201473}
\maketitle
 
\begin{problem}{1} 
  Consider the integral function
  \[
    J[y] = \int_{1}^{2}\frac{y'(x)^2}{x}dx
  \]
  The integrand here is strongly convex (on an appropriately defined set).
  Find the unique \(y \in D\) that minimizes \(J[y]\) over D, for the following cases.
  In each case, is the minimizer (if it exists) unique?
\end{problem}

\begin{subproblem}{a}
  \(D=\{y \in C^1[1,2]:y(1) = 0, y(2) = 3\}\)
\end{subproblem}

\begin{solution}
  $ $\\
  If J is a minimum at \(y \in D \) then \(y\) must satify the Euler-Lagrange equation
  \\\(F_y(x,y,y') - \frac{d}{dx}F_{y'}(x,y,y') = 0\) where \(F(x,y,y') = \frac{y'(x)^2}{x}\).
  \begin{align*}
    \frac{\partial F}{\partial y} - \frac{d}{dx}\frac{\partial F}{\partial y'} = 0
    &\lra \frac{\partial F}{\partial y} = \frac{d}{dx}\frac{\partial F}{\partial y'} \\
    &\lra 0 = \frac{d}{dx}\frac{2y'}{x} \lra \int 0 dx = \int \frac{d}{dx}\frac{2y'}{x} dx \\
    &\lra \frac{2y'}{x} = C \quad (C \in \R) \\
    &\lra y' = Bx \quad (B \in \R) \\
    &\lra \int y' dx = \int Bx dx \\
    &\lra y = c_1x^2 + c_2 \quad (c1,c2 \in \R)
  \end{align*}
  \(y\) must also satisfy the boundary conditions:
  \[
    \left\{
      \begin{array}{ll}
        y(1) = c_1 + c_2 = 0\\
        y(2) = 4c_1 + c_2 = 3\\
      \end{array}
    \right.
    \lra c_1 = \frac{3}{5}, c_2 = -\frac{3}{5} \lra \boxed{y = \frac{3}{5}x^2 - \frac{3}{5}}
  \]
  We have shown with Euler-Lagrange equation the necessary conditions for \(y\) to minimize \(J[y]\)
  and because we are given the integrand is strongly convex on the defined set D, we have
  the sufficient conditions to guarantee \(y\) is the unique minimizer.
\end{solution}
\clearpage
\begin{subproblem}{b}
  \(D = \{y \in C^1[1,2]:y(2) = 3\}\)
\end{subproblem}

\begin{solution}
  $ $\\
  From the notes given in class, we have the following:
  \begin{theorem*}{}
  If \(F(x,y,y')\) is strongly convex in \((y,y')\) then a solution \(y(x)\) of the
  Differential Euler-Lagrange equation uniquely minimizes
  \[
    J[y] = \int_{a}^{b}F(x,y,y')dx
  \]
  over \(\{y \in C'[a,b] : y(b) = B\} \) if \(F_{y'}(a,y(a),y'(a)) = 0\).
  \end{theorem*}
  $ $\\
  We find the solution to the Euler-Lagrange equation \(F_y(x,y,y') -
  \frac{d}{dx}F_{y'}(x,y,y') = 0\) where \(F(x,y,y') = \frac{y'(x)^2}{x}\).
  \begin{align*}
    \frac{\partial F}{\partial y} - \frac{d}{dx}\frac{\partial F}{\partial y'} = 0
    &\lra \frac{\partial F}{\partial y} = \frac{d}{dx}\frac{\partial F}{\partial y'} \\
    &\lra 0 = \frac{d}{dx}\frac{2y'}{x} \lra \int 0 dx = \int \frac{d}{dx}\frac{2y'}{x} dx \\
    &\lra \frac{2y'}{x} = C \quad (C \in \R) \\
    &\lra y' = Bx \quad (B \in \R) \\
    &\lra \int y' dx = \int Bx dx \\
    &\lra y = c_1x^2 + c_2 \quad (c1,c2 \in \R)
  \end{align*}
  \(y\) must also satisfy the boundary condition:
  \begin{align*}
    y(2) = 4c_1 + c_2 = 3 
    &\lra c_2 = 3-4c_1 \\
    &\lra y = c_1x^2 + (3-4c_1) \\
    &\lra y = c_1(x^2-4)+3
  \end{align*}
  thus
  \begin{align*}
    F_{y'}(1,y(1),y'(1)) = 0 &\lra \frac{2y'(1)}{1} = 0 \\
                             &\lra y'(1) = 0 \\
                             &\lra 2c_1(1) \\
                             &\lra c_1 = 0
  \end{align*}
  which implies
  \begin{align*}
    \boxed{y(x) = 3}
  \end{align*}
  Given the integrand is strongly convex on the defined set \(D\) along with the theorem
  mentioned above, \(y\) uniquely minimizes \(J[y]\) over \(D\).
\end{solution}

\clearpage
\begin{subproblem}{c}
  \(D = C^1[1,2]\)
\end{subproblem}
\begin{solution}
  $ $\\
  If J is a minimum at \(y \in D \) then \(y\) must satify the Euler-Lagrange equation
  \\\(F_y(x,y,y') - \frac{d}{dx}F_{y'}(x,y,y') = 0\) where \(F(x,y,y') = \frac{y'(x)^2}{x}\).
  \begin{align*}
    \frac{\partial F}{\partial y} - \frac{d}{dx}\frac{\partial F}{\partial y'} = 0
    &\lra \frac{\partial F}{\partial y} = \frac{d}{dx}\frac{\partial F}{\partial y'} \\
    &\lra 0 = \frac{d}{dx}\frac{2y'}{x} \lra \int 0 dx = \int \frac{d}{dx}\frac{2y'}{x} dx \\
    &\lra \frac{2y'}{x} = C \quad (C \in \R) \\
    &\lra y' = Bx \quad (B \in \R) \\
    &\lra \int y' dx = \int Bx dx \\
    &\lra y = c_1x^2 + c_2 \quad (c1,c2 \in \R)
  \end{align*}
  From strong convexity and observation we see if \(y = c_2\), we achieve a minimum for \\
  \(J[y] = \int_{1}^{2}\frac{y'(x)^2}{x}dx\) since \(y'(x)^2 \ge 0\) and
  \(x \in [1,2]\) which implies \(J[y] \ge 0\). However \(y\) is not a unique minimizer
  since \(c2 \in \R\).
  
\end{solution}
\clearpage
\begin{problem}{2}
  Let \(\delta(x)\) be the Dirac delta function. Justify the identity
  \[
    \delta(1-x^2) = \frac{\delta(x-1)+\delta(x+1)}{2}
  \]
  . \\
  Hint: consider the integral \(\int_{-\infty}^{\infty}\delta(1-x^2)dx\)
\end{problem}
\begin{solution}
  For any continuous function f(x), we have
  \[
    \int_{\infty}^{\infty}f(x)\delta(1-x^2)dx =
    \underbrace{\int_{0}^{\infty}f(x)\delta(1-x^2)dx}_\text{(1)} +
    \underbrace{\int_{-\infty}^{0}f(x)\delta(1-x^2)dx}_\text{(2)}
  \]
  If we let \(\sqrt{u} = x\) and \(\frac{1}{2\sqrt{u}}du = dx\)
  \[
    (1) = \int_{0}^{\infty}\frac{f(\sqrt{u})\delta(1-u)}{2\sqrt{u}}du = \frac{f(1)}{2}
  \]
  If we let \(-\sqrt{u} = x\) and \(-\frac{1}{2\sqrt{u}}du = dx\)
  \[
    (2) = -\int_{-\infty}^{0}\frac{f(-\sqrt{u})\delta(1-u)}{2\sqrt{u}}du
    = \int_{0}^{\infty}\frac{f(-\sqrt{u})\delta(1-u)}{2\sqrt{u}}du
    = \frac{f(-1)}{2}
  \]
  thus
  \begin{align*}
    \int_{\infty}^{\infty}f(x)\delta(1-x^2)dx
    &= \frac{1}{2}[f(1) + f(-1)] \\
    &= \frac{1}{2}\bigg[\int_{-\infty}^{\infty}f(x)\delta(x-1)dx +
      \int_{-\infty}^{\infty}f(x)\delta(x+1)dx\bigg] \\
    &= \frac{1}{2}\int_{-\infty}^{\infty}f(x)(\delta(x-1) + \delta(x+1)) dx \\
    &= \int_{-\infty}^{\infty}f(x)\frac{\delta(x-1) + \delta(x+1)}{2} dx
  \end{align*}
  Since \(\delta\) functions are defined only by how they behave in integrals we conclude
  \[
    \boxed{\delta(1-x^2) = \frac{\delta(x-1)+\delta(x+1)}{2}}
  \]
\end{solution}
\clearpage
\begin{problem}{3}
  Let \(f : [0,1] \rightarrow \R\) be a given continuous function,
  and consider the following differential equation for the function \(y\):
  \begin{align}
    \left\{
      \begin{array}{ll}
        y'''(x) = f(x) \qquad\qquad\qquad 0 \le x \le 1 \\
        y(0) = y'(0) = y''(0) = 0
      \end{array}
    \right.
  \end{align}
  Intuitively, finding \(y(x)\) requires three integrations. This problem illustrates that
  by employing a Green's function we can actually find \(y\) via a $single$ integral.
\end{problem}
\begin{subproblem}{a}
  Show that if the Green's function \(u = G(x:s)\) satisfies
  \[
    \left\{
      \begin{array}{ll}
        u'''(x) = \delta(x-s) \qquad\qquad\qquad 0 \le x \le 1 \\
        u(0) = u'(0) = u''(0) = 0
      \end{array}
    \right.
  \]
  then the function
  \begin{align}
    y(x) = \int_{0}^{1}f(s)G(x:s)ds
  \end{align}
  satisfies (1).
  
  
\end{subproblem}

\end{document}
              
            